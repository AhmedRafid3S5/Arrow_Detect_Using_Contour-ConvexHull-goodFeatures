{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 : Run this cell\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_histogram(image):\n",
    "    histogram = np.zeros(256, dtype=int)\n",
    "\n",
    "    for pixel_value in image.flatten():\n",
    "        histogram[pixel_value] += 1\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_histogram_equalization(image, size, stride):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = gray_image.shape\n",
    "\n",
    "    result = np.zeros((height, width))\n",
    "\n",
    "    for i in range(0, height, stride):\n",
    "        for j in range(0, width, stride):\n",
    "            local_region = gray_image[i : min(i + size, height), j : min(j + size, width)]\n",
    "            hist = my_histogram(local_region)\n",
    "            cdf = hist.cumsum()\n",
    "\n",
    "            cdf_min = cdf[cdf > 0].min()  # the minimum non-zero value in the CDF\n",
    "\n",
    "            cdf_normalized = (cdf - cdf_min) * 255 / (cdf[-1] - cdf_min)  # normalizing\n",
    "            # cdf_normalized = (cdf * 255) / cdf.max()\n",
    "            equalized_local_region = cdf[local_region].astype(np.uint8)\n",
    "\n",
    "            result[i : min(i + size, height), j : min(j + size, width)] = equalized_local_region\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to test arrow image in feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    height,width,channels  = frame.shape\n",
    "    #print(height,width)\n",
    "    if not ret:\n",
    "        break\n",
    "    neg_img = 255 - frame\n",
    "    processed_img = local_histogram_equalization(neg_img,64,32)\n",
    "    cv2.imshow('Original Image',frame)\n",
    "    cv2.imshow('Negative Image',neg_img)\n",
    "    cv2.imshow('Processed Image',processed_img)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 : Run this cell\n",
    "#Utility Functions for arrow tip detection\n",
    "\n",
    "#Image preprocessor\n",
    "def preprocess(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_blur = cv2.GaussianBlur(img_gray, (5, 5), 1)\n",
    "    img_canny = cv2.Canny(img_blur, 50, 50)\n",
    "    kernel = np.ones((3, 3))\n",
    "    img_dilate = cv2.dilate(img_canny, kernel, iterations=2)\n",
    "    img_erode = cv2.erode(img_dilate, kernel, iterations=1)\n",
    "    return img_erode\n",
    "\n",
    "# Function to match common points between contours and corners\n",
    "def match_points(contour, good_features, threshold=10):\n",
    "    matched_points = []\n",
    "    for pt in good_features:\n",
    "        for cnt_pt in contour:\n",
    "            dist = np.linalg.norm(cnt_pt[0] - pt)  # Access the [0] index for the point\n",
    "            if dist < threshold:\n",
    "                matched_points.append(cnt_pt[0])  # Store only the coordinates\n",
    "    return matched_points\n",
    "\n",
    "def find_tip(points, convex_hull):\n",
    "    length = len(points)\n",
    "    indices = np.setdiff1d(range(length), convex_hull)\n",
    "\n",
    "    for i in range(2):\n",
    "        j = indices[i] + 2\n",
    "        if j > length - 1:\n",
    "            j = length - j\n",
    "        if np.all(points[j] == points[indices[i - 1] - 2]):\n",
    "            return tuple(points[j])\n",
    "# Function to find the tail of the arrow\n",
    "def find_tail(points, tip):\n",
    "    # Find the point farthest from the tip\n",
    "    max_dist = -1\n",
    "    tail_point = None\n",
    "    \n",
    "    for point in points:\n",
    "        point = tuple(point[0])\n",
    "        dist = np.linalg.norm(np.array(point) - np.array(tip))\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "            tail_point = point\n",
    "            \n",
    "    return tail_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 : Run this cell\n",
    "#Iterative template matching function to find the best template & the best scale\n",
    "\n",
    "methods = [cv2.TM_CCOEFF, cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR,\n",
    "            cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]\n",
    "\n",
    "#return co-od required to build a rectangle\n",
    "def iterative_match(frame, template_img_lft,template_img_right):\n",
    "    MATCH_THRESHOLD = 0.1\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert frame to grayscale\n",
    "    best_value = -1\n",
    "    best_location = (-1, -1)\n",
    "    best_scale = -1\n",
    "    best_template_flag = '' \n",
    "    best_template = None\n",
    "\n",
    "    for scale in np.arange(0.1, 2, 0.01):\n",
    "        resized_template = 255 - cv2.resize(cv2.imread('right_arrow_template.png', 0), (0, 0), fx=scale, fy=scale)\n",
    "        resized_template_left = 255 - cv2.resize(cv2.imread('left_arrow_template.png', 0), (0, 0), fx=scale, fy=scale)\n",
    "        \n",
    "        # Ensure the template size is smaller than the frame size\n",
    "        if resized_template.shape[0] > gray_frame.shape[0] or resized_template.shape[1] > gray_frame.shape[1]:\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        result = cv2.matchTemplate(gray_frame, resized_template, methods[1])  # Using CCOEFF_NORMED\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        left_test_result = cv2.matchTemplate(gray_frame, resized_template_left, methods[1])\n",
    "        lft_t_min,lft_t_max,lft_t_min_loc,lft_t_max_loc = cv2.minMaxLoc(left_test_result)\n",
    "\n",
    "        if max_val > best_value and max_val > MATCH_THRESHOLD:  # Use 'and' instead of '&'\n",
    "            best_value = max_val\n",
    "            best_location = max_loc\n",
    "            best_scale = scale\n",
    "            best_template_flag = 'R'\n",
    "        \n",
    "        if lft_t_max > best_value and lft_t_max > MATCH_THRESHOLD:  # Use 'and' instead of '&'\n",
    "            best_value = lft_t_max\n",
    "            best_location = lft_t_max_loc\n",
    "            best_scale = scale\n",
    "            best_template_flag = 'L'\n",
    "        \n",
    "        if best_template_flag == 'R':\n",
    "            best_template = template_img_right\n",
    "        elif best_template_flag == 'L':\n",
    "            best_template = template_img_lft\n",
    "            \n",
    "    \n",
    "    if best_location[0] != -1 and best_location[1] != -1:  # Use 'and' instead of '&'\n",
    "        h, w = best_template.shape\n",
    "        w = int(w * best_scale)\n",
    "        h = int(h * best_scale)\n",
    "\n",
    "        top_left = best_location\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        return top_left, bottom_right, best_template_flag\n",
    "    return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "R\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "L\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "L\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "R\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "R\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "R\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "R\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "L\n",
      "R\n",
      "R\n",
      "R\n"
     ]
    }
   ],
   "source": [
    "#Finally run this\n",
    "#Main driver function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "#Grey scale of template\n",
    "right_arrow_template = cv2.imread('right_arrow_template.png',0)\n",
    "left_arrow_template = cv2.imread('left_arrow_template.png',0)\n",
    "\n",
    "#taking negative of the templates as well\n",
    "right_arrow_template = 255 - right_arrow_template\n",
    "left_arrow_template = 255 - left_arrow_template\n",
    "\n",
    "roi = cv2.imread('right_arrow_template.png',0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.05, minDistance=7, blockSize=7)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    #take negative\n",
    "    frame = 255 - frame\n",
    "    red_rect_top, red_rect_botm,direction = iterative_match(frame,left_arrow_template,right_arrow_template)\n",
    "    \n",
    "    x1 = red_rect_top[0]\n",
    "    x2 = red_rect_botm[0]\n",
    "    y1 = red_rect_top[1]\n",
    "    y2 = red_rect_botm[1]\n",
    "\n",
    "    roi = frame[y1:y2,x1:x2]\n",
    "    print(direction)\n",
    "    # Draw rectangles if matches are found\n",
    "    if red_rect_top and red_rect_botm:\n",
    "        #print(\"Detected\")\n",
    "        cv2.rectangle(frame, red_rect_top, red_rect_botm, (0, 0, 255), 5)  # Red rectangle for right arrow\n",
    "    \n",
    "    \n",
    "    #Detect direction -----------------------------------------------------------------------------------------------\n",
    "    # Preprocess the frame\n",
    "    extracted_frame = roi\n",
    "    preprocessed = preprocess(extracted_frame)\n",
    "    \n",
    "    # Detect contours\n",
    "    contours, hierarchy = cv2.findContours(preprocessed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Detect good features to track\n",
    "    frame_gray = cv2.cvtColor(extracted_frame, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(frame_gray)\n",
    "    mask[:] = 255\n",
    "    corners = cv2.goodFeaturesToTrack(frame_gray, mask=None, **feature_params)\n",
    "#\n",
    "    if corners is not None:\n",
    "       corners = corners.reshape((-1, 2))\n",
    "\n",
    "       for contour in contours:\n",
    "           # Find the points on the contour that match the detected corners\n",
    "           matched_points = match_points(contour, corners)\n",
    "\n",
    "           # If a certain number of points match, classify it as a possible arrow\n",
    "           if len(matched_points) > 5:  # Adjust threshold as needed\n",
    "               cv2.drawContours(extracted_frame, [contour], -1, (0, 255, 0), 2)\n",
    "               \n",
    "               # Draw matched points\n",
    "               for pt in matched_points:\n",
    "                 cv2.circle(extracted_frame, (pt[0], pt[1]), 3, (0, 0, 255), -1)\n",
    "               \n",
    "               for cnt in [contour]:\n",
    "                peri = cv2.arcLength(cnt, True)\n",
    "                approx = cv2.approxPolyDP(cnt, 0.025 * peri, True)\n",
    "                hull = cv2.convexHull(approx, returnPoints=False)\n",
    "                sides = len(hull)\n",
    "                #print(sides)\n",
    "  \n",
    "                if 6 > sides > 3 and sides + 2 == len(approx):\n",
    "                   arrow_tip = find_tip(approx[:,0,:], hull.squeeze())\n",
    "                   if arrow_tip:\n",
    "                       #print(arrow_tip)\n",
    "                       tail_tip = find_tail(approx,arrow_tip)\n",
    "                       #cv2.drawContours(img, [cnt], -1, (0, 255, 0), 3)\n",
    "                       cv2.circle(extracted_frame, arrow_tip, 3, (0, 0, 255), cv2.FILLED)\n",
    "                       cv2.circle(extracted_frame,tail_tip,3,(255,0,0),cv2.FILLED)\n",
    "                       #cv2.circle(extracted_frame,(tail_tip+arrow_tip)/2,3,(0,255,0),cv2.FILLED)\n",
    "                       #print(\"Tip: \",arrow_tip,\" Tail: \",tail_tip)\n",
    "                       midpoint_x = (arrow_tip[0] + tail_tip[0]) // 2\n",
    "                       midpoint_y = (arrow_tip[1] + tail_tip[1]) // 2\n",
    "                       midpoint = (midpoint_x, midpoint_y)\n",
    "                       if arrow_tip[0] - tail_tip[0] > 0:\n",
    "                           cv2.putText(extracted_frame, \"Pointing Right\", midpoint, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                           #print(\"Pointing Right\")\n",
    "                       else :\n",
    "                           cv2.putText(extracted_frame, \"Pointing Left\", midpoint, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                           #print(\"Pointing Left\")\n",
    "    \n",
    "    #for cnt in contours:\n",
    "    #  peri = cv2.arcLength(cnt, True)\n",
    "    #  approx = cv2.approxPolyDP(cnt, 0.025 * peri, True)\n",
    "    #  hull = cv2.convexHull(approx, returnPoints=False)\n",
    "    #  sides = len(hull)\n",
    "  #\n",
    "    #  if 6 > sides > 3 and sides + 2 == len(approx):\n",
    "    #      arrow_tip = find_tip(approx[:,0,:], hull.squeeze())\n",
    "    #      if arrow_tip:\n",
    "    #          tail_tip = find_tail(approx,arrow_tip)\n",
    "    #          cv2.drawContours(extracted_frame, [cnt], -1, (0, 255, 0), 3)\n",
    "    #          cv2.circle(extracted_frame, arrow_tip, 3, (0, 0, 255), cv2.FILLED)\n",
    "    #          cv2.circle(extracted_frame,tail_tip,3,(255,0,0),cv2.FILLED)\n",
    "    #          print(\"Tip: \",arrow_tip,\" Tail: \",tail_tip)\n",
    "    #          if arrow_tip[0] - tail_tip[0] > 0:\n",
    "    #              cv2.putText(frame, \"Pointing Right\", arrow_tip, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    #          else :\n",
    "#cv2.putText(frame, \"Pointing Left\", arrow_tip, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow(\"Arrow Detection\",frame)\n",
    "\n",
    "    cv2.imshow('Extracted arrow',extracted_frame)\n",
    "    #cv2.imshow('Extracted Image',roi)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
